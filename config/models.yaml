# 12 models used across Figures 2 and 3.
# Figure 2: pretrained + instruction-tuned pairs (gemma-2-2b, Llama-3.2-3B)
# Figure 3: instruction-tuned models only (10 models, MWLR lollipop)

# Gemma family
- name: google/gemma-2-2b
  type: pretrained
  family: gemma
  dtype: bfloat16

- name: google/gemma-2-2b-it
  type: instruction-tuned
  family: gemma
  dtype: bfloat16

- name: google/gemma-2-9b-it
  type: instruction-tuned
  family: gemma
  dtype: bfloat16

- name: google/gemma-2-27b-it
  type: instruction-tuned
  family: gemma
  dtype: bfloat16

# Llama family
- name: meta-llama/Llama-3.2-3B
  type: pretrained
  family: llama
  dtype: bfloat16

- name: meta-llama/Llama-3.2-3B-Instruct
  type: instruction-tuned
  family: llama
  dtype: bfloat16

- name: meta-llama/Llama-3.2-1B-Instruct
  type: instruction-tuned
  family: llama
  dtype: bfloat16

- name: meta-llama/Meta-Llama-3-8B-Instruct
  type: instruction-tuned
  family: llama
  dtype: bfloat16

- name: meta-llama/Llama-3.1-8B-Instruct
  type: instruction-tuned
  family: llama
  dtype: bfloat16

- name: meta-llama/Meta-Llama-3-70B-Instruct
  type: instruction-tuned
  family: llama
  dtype: bfloat16

- name: meta-llama/Llama-3.1-70B-Instruct
  type: instruction-tuned
  family: llama
  dtype: bfloat16

- name: meta-llama/Llama-3.3-70B-Instruct
  type: instruction-tuned
  family: llama
  dtype: bfloat16
